# Artificial Incompetence

In AI, a lot of things can go wrong.

The goal of AI is to perform tasks normally performed by humans.
https://en.wikipedia.org/wiki/The_Imitation_Game

Machine learning is a part of AI, focussing on mimicking human behaviour.
I give the model lots of dog pictures, after a while, the system can
recognize dogs. The AI system is never 100% sure.

beauty.ai:

- beauty contest judged by AI
- based on certain characteristics, a percentage of beauty was given, e.g. symmetry
- most of the finalists where white, only one people of color. Result: the robot was racist as fuck.

scottish championship:

- replace cameraman with an AI system following the ball
- the bald ref was the bald

natural language processing:

- branch of AI that is concerned with understanding text and spoken words like humans do
- english -> turkish -> english in google translate has gender bias
    - AI preferred male over female candidates, AI was sexist as fuck.
- when output is used as training for the new model, the model becomes more and more sexist.

Microsoft Tay

- Twitterbot, learned from interactions. Became racist as fuck.

Amazon Alexa

- Just ordered a wish from Amazon. Was reported on TV, all listeners also goth ordered the same dollhouse.

Takeaway: it is our responsibility to provider proper training data